# Project Management Success Prediction

This repository contains a **synthetic data project** designed to showcase the workflow a business analyst, program manager or data analyst might follow when exploring and modelling data.  The project includes a dataset generator, an analysis notebook, installation instructions and a summary of results.  Although the data are synthetic, the variables resemble those encountered in project‑management and product‑development settings.

## Overview

Classification methods try to predict which class or category an entity belongs to based on its features【210255567251342†L141-L152】.  In the context of project management, you might try to model the likelihood that a project will succeed given inputs such as team size, duration, budget, risk and scope volatility.  The synthetic dataset in this repository simulates 500 projects with the following fields:

| Column | Description |
|-------|-------------|
| `project_id` | Unique identifier for each project |
| `team_size` | Number of people on the project team |
| `duration_days` | Duration of the project in days |
| `budget_k_usd` | Budget allocated to the project in thousands of USD |
| `complexity` | Project complexity score on a 1–10 scale (higher means more complex) |
| `stakeholder_count` | Number of stakeholders associated with the project |
| `scope_changes` | Number of scope change requests during the project |
| `risk_score` | Risk score from 0 to 100 (higher means higher risk) |
| `on_schedule` | Binary indicator (1 if the project finished on schedule, 0 otherwise) |
| `on_budget` | Binary indicator (1 if the project stayed within its budget, 0 otherwise) |
| `customer_satisfaction` | Customer satisfaction rating on a 1–5 scale |
| `overall_success` | Target variable indicating overall success (1 for success, 0 for failure) |

The dataset is generated by sampling reasonable ranges for each characteristic and imposing probabilistic relationships between risk, complexity, schedule adherence and budget adherence to determine overall success.  **No real project data are used**.

## Repository Structure

- `project_management_dataset.csv` – the synthetic dataset used for analysis (500 rows × 12 columns).
- `analysis.ipynb` – a Jupyter notebook that performs exploratory data analysis, visualisations, correlation analysis and predictive modelling (logistic regression and random forest).
- `requirements.txt` – lists Python packages required to run the notebook.
- `README.md` – this document.

## Getting Started

Follow these steps to run the analysis locally:

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/project-management-success.git
   cd project-management-success
   ```

2. **Set up a virtual environment (optional but recommended)**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Launch Jupyter Notebook**
   ```bash
   jupyter notebook analysis.ipynb
   ```

   Once the notebook opens in your browser, execute each cell to reproduce the exploratory analyses, charts and predictive models.

## Summary of Results

Running the notebook will produce descriptive statistics and charts showing how variables such as budget, complexity and risk distribute across the simulated projects.  A correlation heatmap visualises relationships between all features and the `overall_success` target.  The modelling section splits the data into training and test sets, scales continuous features for logistic regression and fits both a logistic regression model and a random forest classifier.  On the synthetic data, the random forest slightly outperforms logistic regression in terms of accuracy and area under the ROC curve, but both achieve high performance because the target is generated directly from the features.  The conclusion section of the notebook discusses the results and points out that real-world data typically require more careful feature engineering and domain knowledge.

## Extending the Project

- Experiment with different model types (e.g., gradient boosting, support‑vector machines) and hyperparameters.
- Generate larger datasets or alter the probability functions in the data generator to simulate different organisational behaviours.
- Incorporate categorical variables (e.g., project methodology, industry sector) and use one‑hot encoding for modelling.
- Use the trained models to predict outcomes for hypothetical future projects.

## License

This project is provided for educational purposes under the MIT License.  Feel free to use or modify the code and dataset to suit your learning or portfolio needs.
