{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16bf14e",
   "metadata": {},
   "source": [
    "# Project Management Success Prediction\n",
    "\n",
    "This notebook demonstrates an end-to-end analysis and predictive modeling workflow for a synthetic project management dataset.\n",
    "\n",
    "We generate a dataset that includes project characteristics—such as team size, project duration (in days), budget (k USD), complexity rating, stakeholder count, number of scope changes and risk score—and outcomes such as whether the project stayed on schedule and budget, customer satisfaction, and overall success.\n",
    "\n",
    "The goals of this notebook are:\n",
    "\n",
    "* **Exploratory data analysis (EDA):** compute summary statistics and visualize feature distributions and relationships.\n",
    "* **Correlation analysis:** explore relationships between project variables and outcomes.\n",
    "* **Predictive modeling:** build classification models to estimate the probability that a project will be successful. We try logistic regression and random forest algorithms, evaluate their performance on a held‑out test set, and inspect classification metrics.\n",
    "\n",
    "Feel free to modify the data generation or modeling steps to explore different scenarios!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cba30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic dataset\n",
    "# The CSV file is generated separately; make sure project_management_dataset.csv is in the same directory\n",
    "\n",
    "df = pd.read_csv('project_management_dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c780fa",
   "metadata": {},
   "source": [
    "## Overview of the dataset\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "| Column | Description |\n",
    "|-------|-------------|\n",
    "| `project_id` | Unique identifier for each project |\n",
    "| `team_size` | Number of people on the project team |\n",
    "| `duration_days` | Duration of the project in days |\n",
    "| `budget_k_usd` | Budget allocated to the project (thousands of USD) |\n",
    "| `complexity` | Project complexity score on a 1–10 scale (higher means more complex) |\n",
    "| `stakeholder_count` | Number of stakeholders associated with the project |\n",
    "| `scope_changes` | Number of scope change requests during the project |\n",
    "| `risk_score` | Risk score from 0 to 100 (higher means higher risk) |\n",
    "| `on_schedule` | Binary indicator (1 if on schedule, 0 otherwise) |\n",
    "| `on_budget` | Binary indicator (1 if on budget, 0 otherwise) |\n",
    "| `customer_satisfaction` | Customer satisfaction rating on a 1–5 scale |\n",
    "| `overall_success` | Target variable indicating overall success (1 for success, 0 for failure) |\n",
    "\n",
    "We will perform exploratory data analysis and predictive modeling on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33206b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric features\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9226071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution of the target variable\n",
    "y_counts = df['overall_success'].value_counts().rename(index={0:'Failure', 1:'Success'})\n",
    "print('Class distribution (Success vs Failure):')\n",
    "print(y_counts)\n",
    "y_counts.plot(kind='bar', color=['salmon','skyblue'])\n",
    "plt.title('Distribution of project success')\n",
    "plt.ylabel('Number of projects')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebef37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key numeric features\n",
    "features = ['team_size', 'duration_days', 'budget_k_usd', 'complexity', 'stakeholder_count', 'scope_changes', 'risk_score', 'customer_satisfaction']\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 16))\n",
    "for idx, feature in enumerate(features):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    sns.histplot(df[feature], ax=ax, kde=True, color='steelblue')\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02103761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix and heatmap\n",
    "corr = df.drop(columns=['project_id']).corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation matrix of project features and outcomes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore how complexity relates to project success\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='overall_success', y='complexity', data=df, palette='Set2')\n",
    "plt.title('Complexity vs. Overall Success')\n",
    "plt.xlabel('Overall Success (0 = Failure, 1 = Success)')\n",
    "plt.ylabel('Complexity score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = df[['team_size', 'duration_days', 'budget_k_usd', 'complexity', 'stakeholder_count', 'scope_changes', 'risk_score', 'on_schedule', 'on_budget', 'customer_satisfaction']]\n",
    "y = df['overall_success']\n",
    "\n",
    "# Train‑test split with stratification\n",
    "test_size = 0.25\n",
    "random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "# Scale continuous features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_prob_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('Logistic Regression Accuracy:', round(accuracy_score(y_test, y_pred_lr), 3))\n",
    "print('\n",
    "Classification Report:\n",
    "', classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix: Logistic Regression')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7622166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('Random Forest Accuracy:', round(accuracy_score(y_test, y_pred_rf), 3))\n",
    "print('\n",
    "Classification Report:\n",
    "', classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix: Random Forest')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c152f5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we explored a synthetic project management dataset. After performing basic exploratory data analysis and visualizing the distributions and correlations of various project features, we trained logistic regression and random forest classifiers to predict whether a project would be successful. Both models achieved high accuracy and AUC scores, with the random forest slightly outperforming the logistic regression model in this synthetic setting.\n",
    "\n",
    "This analysis demonstrates how project characteristics (such as team size, complexity, risk score and resource constraints) can influence project outcomes. In real-world scenarios, additional domain knowledge and feature engineering would be essential to build robust predictive models. Feel free to experiment with different algorithms, parameter settings, or additional features to further improve predictive performance.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
